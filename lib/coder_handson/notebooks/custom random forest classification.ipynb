{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "tags": [],
    "createdOn": 1617637349351,
    "creator": "msakande",
    "customFields": {},
    "modifiedBy": "admin",
    "hide_input": false
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd, numpy as np"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# load \u0027train\u0027 dataset as a Pandas dataframe\ndf \u003d dataiku.Dataset(\"train\").get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Dataset Settings\n#-----------------------------------------------------------------\n\n# Select a subset of features to use for training\nSCHEMA \u003d {    \n    \u0027target\u0027: \u0027high_value\u0027,    \n    \u0027features_num\u0027: [\u0027age\u0027, \u0027price_first_item_purchased\u0027, \u0027pages_visited\u0027],    \n    \u0027features_cat\u0027: [\u0027gender\u0027, \u0027campaign\u0027]    \n}"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Preprocessing on Training Set\n#-----------------------------------------------------------------\n\n# Numerical variables\ndf_num \u003d df[SCHEMA[\u0027features_num\u0027]]\n\ntrf_num \u003d Pipeline([\n    (\u0027imp\u0027, SimpleImputer(strategy\u003d\u0027mean\u0027)),\n    (\u0027sts\u0027, StandardScaler()),\n])\n\nx_num \u003d trf_num.fit_transform(df_num)\n\n# Categorical variables\ndf_cat \u003d df[SCHEMA[\u0027features_cat\u0027]]\nfeatures \u003d df_cat.columns\n\nfor feature in features:\n    if df_cat[feature].dtype !\u003d \u0027object\u0027:\n        df_cat[feature] \u003d df_cat[feature].astype(str)\n\ndata \u003d df_cat.to_dict(orient\u003d\u0027records\u0027)\n        \ntrf_cat \u003d DictVectorizer(sparse\u003dFalse)\nx_cat \u003d trf_cat.fit_transform(data)\n\n# Concat \nX \u003d np.concatenate((x_cat, x_num), axis\u003d1)\nY \u003d df[SCHEMA[\u0027target\u0027]].values"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-------------------------------------------------------------------------\n# TRAINING\n#-------------------------------------------------------------------------\n\nparam_grid \u003d {\n    \"max_depth\"        : [3, None],\n    \"max_features\"     : [1, 3, 5],\n    \"min_samples_split\": [2, 3, 10],\n    \"min_samples_leaf\" : [1, 3, 10],\n    \"bootstrap\"        : [True, False],\n    \"criterion\"        : [\"gini\", \"entropy\"],\n    \"n_estimators\"     : [5, 10]\n}\n\nclf \u003d RandomForestClassifier()\ngs \u003d GridSearchCV(clf, param_grid\u003dparam_grid, n_jobs\u003d-1, scoring\u003d\u0027roc_auc\u0027, cv\u003d3)\ngs.fit(X, Y)\nclf \u003d gs.best_estimator_"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Preprocessing on Test Set\n#-----------------------------------------------------------------\n\n# load \u0027test\u0027 dataset as a Pandas dataframe\ndf_test \u003d dataiku.Dataset(\"to_assess_prepared\").get_dataframe()\n\n#-----------------------------------------------------------------\n# Transform and score test set\n#-----------------------------------------------------------------\n\n# Preprocess numerical features\nx_test_num \u003d trf_num.transform( df_test[SCHEMA[\u0027features_num\u0027]] )\n\n# Preprocess categorical features\ndf_test_cat \u003d df_test[SCHEMA[\u0027features_cat\u0027]]\nfeatures \u003d df_test_cat.columns\n\nfor feature in features:\n    if df_test_cat[feature].dtype !\u003d \u0027object\u0027:\n        df_test_cat[feature] \u003d df_test_cat[feature].astype(str)\ndata \u003d df_test_cat.to_dict(orient\u003d\u0027records\u0027)\n\nx_test_cat \u003d trf_cat.transform( data )\n\n# Concatenate\nX_test \u003d np.concatenate((x_test_cat, x_test_num), axis\u003d1)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Actually score the new records\nscores \u003d clf.predict_proba(X_test)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#-----------------------------------------------------------------\n# Reshape\n#-----------------------------------------------------------------\npreds \u003d pd.DataFrame(scores, index\u003ddf_test.index).rename(columns\u003d{0: \u0027proba_False\u0027, 1: \u0027proba_True\u0027})\nall_preds \u003d df_test.join(preds)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sample of the test dataset with predicted probabilities\nall_preds.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute AUC results\n\nauc \u003d roc_auc_score(all_preds[\u0027high_value\u0027].astype(bool).values, all_preds[\u0027proba_True\u0027].values)\nauc"
      ],
      "outputs": []
    }
  ]
}