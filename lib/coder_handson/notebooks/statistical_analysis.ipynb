{
  "metadata": {
    "createdOn": 1617634652885,
    "creator": "msakande",
    "customFields": {},
    "hide_input": false,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin",
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Univariate analysis is perhaps the simplest form of statistical analysis. The key fact is that only one variable is involved.\n\n\u003ccenter\u003e\u003cstrong\u003eSelect Cell \u003e Run All to execute the whole analysis\u003c/strong\u003e\u003c/center\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and dataset loading \u003ca id\u003d\"setup\" /\u003e \n\nFirst of all, let\u0027s load the libraries that we\u0027ll use"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku                               # Access to Dataiku datasets\nimport pandas as pd, numpy as np             # Data manipulation \nfrom matplotlib import pyplot as plt         # Graphing\nimport seaborn as sns                        # Graphing\nimport warnings                              # Disable some warnings\nwarnings.filterwarnings(\"ignore\",category\u003dDeprecationWarning)\nfrom scipy import stats                      # Stats"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first thing we do is now to load the dataset and put aside the three main types of columns:\n\n* Numerics\n* Categorical\n* Dates\n\nStatistical analysis requires having the data in memory, we are only going to load a sample of the data. Modify the following cell to change the size of the sample."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_limit \u003d 10000"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a DSS dataset as a Pandas dataframe. ***UPDATE LINE 3 WITH THE NAME OF YOUR DATASET***"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: UPDATE LINE 3 WITH THE NAME OF YOUR DATASET\n# Take a handle on the dataset\nmydataset \u003d dataiku.Dataset(\"dataset_name\")\n\n# Load the first lines.\n# You can also load random samples, limit yourself to some columns, or only load\n# data matching some filters.\n#\n# Please refer to the Dataiku Python API documentation for more information\ndf \u003d mydataset.get_dataframe(limit \u003d dataset_limit)\n\ndf_orig \u003d df.copy()\n\n# Get the column names\nnumerical_columns \u003d list(df.select_dtypes(include\u003d[np.number]).columns)\ncategorical_columns \u003d list(df.select_dtypes(include\u003d[object]).columns)\ndate_columns \u003d list(df.select_dtypes(include\u003d[\u0027\u003cM8[ns]\u0027]).columns)\n\n# Print a quick summary of what we just loaded\nprint(\"Loaded dataset\")\nprint(\"   Rows: %s\" % df.shape[0])\nprint(\"   Columns: %s (%s num, %s cat, %s date)\" % (df.shape[1], \n                                                    len(numerical_columns), len(categorical_columns),\n                                                    len(date_columns)))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing of the data \u003ca id\u003d\"preprocessing\" /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***UPDATE `value_col` WITH THE NAME OF YOUR COLUMN OF INTEREST***"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "value_col \u003d \u0027COLUMN_OF_INTEREST\u0027\nprint(\"Selected value column is \u0027%s\u0027\" % (value_col))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We drop rows for which `value_col` is missing"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.dropna(subset\u003d[value_col], inplace\u003dTrue)\ndf_pop_1 \u003d df[value_col]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical analysis and vizualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### General statistics\nNumber of records, mean, standard deviation, minimal value, quartiles, maximum value, mode, variance, skewness and kurtosis."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "additional_stats \u003d [\"var\", \"skew\", \"kurtosis\"]\nprint(\"Stats about your series:\\n\", df_pop_1.describe().append(pd.Series(NaN if df_pop_1.mode().empty else df_pop_1.mode()[0], index\u003d[\"mode\"])).append(pd.Series([df_pop_1.__getattr__(x)() for x in additional_stats], index\u003dadditional_stats)))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histogram\nHistograms let you see the number of occurrences in your value column."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.title(\"Histogram of \"+value_col);\nplt.hist(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distplot\nDistplots combine an histogram with a kernel density estimation."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.distplot(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Box plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple way of representing statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles, with a vertical line inside to indicate the median value. The lower and upper quartiles are shown as horizontal lines either side of the rectangle."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.boxplot(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Violin plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The violin plot is similar to box plots, except that they also show the probability density of the data at different values. Violin plots include a marker for the median of the data and a box indicating the interquartile range, as in standard box plots. Overlaid on this box plot is a kernel density estimation. "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.violinplot(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Letter value plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Letter value plots are an improvement upon boxplots for large datasets.\n\nThey display the median and the quartiles, like a standard box plot, but will also draw boxes for subsequent \"eights\", \"sixteenth\" etc... which are generically called letter values.\n\nA cut off condition will leave a reasonable number of outliers out of the final boxes, helping you spot them easily.\n\nLetter value plots give a good sense of the distribution of data, and of its skewness."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.boxenplot(df_pop_1);"
      ],
      "outputs": []
    }
  ]
}